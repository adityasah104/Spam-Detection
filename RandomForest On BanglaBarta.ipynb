{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45af577a-852b-4a2b-86d6-0486822f051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9cc08f-96cd-42c7-9932-c9effaef5a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV file\n",
    "df = pd.read_csv('processed_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff9428-b531-4135-8464-28fc3f854666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nSample of the dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9880358a-b459-444e-879a-67df0560ce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9e4c6b-3a0a-46f9-a947-e7c8a1c472f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values in 'type' column\n",
    "print(\"\\nUnique values in 'type' column:\")\n",
    "print(df['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09fb916-5516-4872-98b8-5c65aa987298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the type values - treat case insensitively and NaN as spam\n",
    "def standardize_type(x):\n",
    "    if pd.isna(x):  # Handle NaN values as spam\n",
    "        return 'spam'\n",
    "\n",
    "    if not isinstance(x, str):\n",
    "        x = str(x)  # Convert non-string types to string\n",
    "\n",
    "    x_lower = x.lower().strip()\n",
    "\n",
    "    # Exact match for main categories\n",
    "    if 'spam' in x_lower:\n",
    "        return 'spam'\n",
    "    elif 'ham' in x_lower:\n",
    "        return 'ham'\n",
    "    elif 'promo' in x_lower:\n",
    "        return 'promo'\n",
    "    else:\n",
    "        return x_lower  # Return as is for other categories\n",
    "\n",
    "df['standardized_type'] = df['label'].apply(standardize_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09f172c-e58c-4315-bebd-522112986ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display distribution of standardized types\n",
    "print(\"\\nStandardized type distribution:\")\n",
    "print(df['standardized_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ddec29-cc33-4573-9670-152aab6109e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label encoder for the target variable\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['type_encoded'] = label_encoder.fit_transform(df['standardized_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b05e5b-9075-4b09-8552-4ebe20f56ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the encoded values back to their original labels for reference\n",
    "encoded_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"\\nEncoded class mapping:\")\n",
    "for class_name, encoded_value in encoded_mapping.items():\n",
    "    print(f\"{class_name} -> {encoded_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2268e9c4-4d9a-46ce-871f-47535d1364cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (all columns except type-related and text columns)\n",
    "features = [col for col in df.columns if col not in ['type', 'text', 'standardized_type', 'type_encoded', 'label']]\n",
    "print(\"\\nFeatures used for classification:\")\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3014326e-3afb-4f17-b40e-803a09bc0873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df[features]\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9435179-9c44-4ed1-8d49-874c93752e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62943ef8-10f3-4c39-8b2a-15c146abab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# First, create copies to avoid modifying the original data\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "# Apply standard scaler only to the numerical columns (avg_word_length and word_length)\n",
    "# This will scale them to have a mean of 0 and standard deviation of 1\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Identify the columns to scale\n",
    "columns_to_scale = ['avg_word_length', 'word_length']\n",
    "# Fit the scaler on the training data and transform both training and test data\n",
    "X_train_scaled[columns_to_scale] = scaler.fit_transform(X_train[columns_to_scale])\n",
    "X_test_scaled[columns_to_scale] = scaler.transform(X_test[columns_to_scale])\n",
    "\n",
    "# To make the values be between 0 and 1 instead of standardized,\n",
    "# we can use MinMaxScaler instead of StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Apply MinMaxScaler to scale to 0-1 range\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_scaled[columns_to_scale] = min_max_scaler.fit_transform(X_train[columns_to_scale])\n",
    "X_test_scaled[columns_to_scale] = min_max_scaler.transform(X_test[columns_to_scale])\n",
    "\n",
    "# Verify the scaled values are between 0 and 1\n",
    "print(\"\\nScaled training data sample (avg_word_length and word_length should be between 0-1):\")\n",
    "print(X_train_scaled[columns_to_scale].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f3e874-ead0-4478-a250-a0154e3fdb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now train a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on both training and test sets\n",
    "y_train_pred = rf_classifier.predict(X_train_scaled)\n",
    "y_test_pred = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "# Calculate accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"\\nRandom Forest Classifier Results:\")\n",
    "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Testing Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Print detailed classification report for test set\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, y_test_pred, target_names=['Ham','Spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab2ffba-450d-4be4-8d66-e41ae8616e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrix for test set\n",
    "print(\"\\nConfusion Matrix (Test Set):\")\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Feature importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': rf_classifier.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab7c982-f6bc-436e-ad9d-14fb1aeede01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "print(\"\\nTraining Random Forest model...\")\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a540c-084b-4aa9-8b51-596c1d57c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop problematic columns\n",
    "X_train_numeric = X_train.select_dtypes(include=['int64', 'float64'])\n",
    "X_test_numeric = X_test.select_dtypes(include=['int64', 'float64'])\n",
    "\n",
    "# Train with only numeric features\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_numeric, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb7d71-d31a-4758-b437-46bfd10426a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on training data\n",
    "train_preds = rf.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "print(f\"\\nTraining accuracy: {train_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f22bdc8-a8cd-4987-a05e-344820187ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Create preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create a pipeline that includes preprocessing and the model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Now you can use the pipeline for prediction\n",
    "train_preds = pipeline.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "print(f\"\\nTraining accuracy: {train_accuracy:.3f}\")\n",
    "\n",
    "# And for test data when ready\n",
    "# test_preds = pipeline.predict(X_test)\n",
    "# test_accuracy = accuracy_score(y_test, test_preds)\n",
    "# print(f\"Test accuracy: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7436ed-64d6-4c43-9566-7d4bce614592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test data\n",
    "test_preds = rf.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "print(f\"Test accuracy: {test_accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfcb6cf-3919-4415-bb44-fcdd113ea8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the original class names for display\n",
    "original_class_names = label_encoder.classes_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd18ad34-3007-4ebc-928c-4927a694daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, test_preds, target_names=original_class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fea997-82e8-4ae6-9e0c-9a2b0109ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "cm = confusion_matrix(y_test, test_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=original_class_names,\n",
    "            yticklabels=original_class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_multiclass.png')\n",
    "print(\"\\nConfusion matrix saved as 'confusion_matrix_multiclass.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ff3263-80a5-495e-aeba-59a75f39fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': rf.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "plt.title('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance_multiclass.png')\n",
    "print(\"Feature importance plot saved as 'feature_importance_multiclass.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1098c1-bcf2-4415-a987-d98fb5d170a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 5 most important features\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "print(feature_importance.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3f4664-39a3-4a09-9d3c-3cf0717716a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters():\n",
    "    print(\"\\nPerforming hyperparameter tuning...\")\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "    # Train with best parameters\n",
    "    best_rf = RandomForestClassifier(**grid_search.best_params_, random_state=42)\n",
    "    best_rf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    best_preds = best_rf.predict(X_test)\n",
    "    best_accuracy = accuracy_score(y_test, best_preds)\n",
    "    print(f\"Tuned model test accuracy: {best_accuracy:.3f}\")\n",
    "\n",
    "    return best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3afe486-1e9a-43cc-aba5-7cedc5f11189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and label encoder\n",
    "import pickle\n",
    "with open('message_classifier_model.pkl', 'wb') as file:\n",
    "    pickle.dump({'model': rf, 'label_encoder': label_encoder, 'features': features}, file)\n",
    "print(\"\\nModel saved as 'message_classifier_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7d861f-834b-4be2-99e1-840a81d3ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions on new data\n",
    "def predict_message_type(model_data, new_data):\n",
    "    # Extract model components\n",
    "    model = model_data['model']\n",
    "    label_encoder = model_data['label_encoder']\n",
    "    features = model_data['features']\n",
    "\n",
    "    # Ensure new_data has the same features as training data\n",
    "    needed_features = [f for f in features if f in new_data.columns]\n",
    "    missing_features = [f for f in features if f not in new_data.columns]\n",
    "\n",
    "    if missing_features:\n",
    "        print(f\"Warning: Missing features: {missing_features}\")\n",
    "        for feature in missing_features:\n",
    "            new_data[feature] = 0  # Add missing features with default values\n",
    "\n",
    "    new_data_features = new_data[features]\n",
    "\n",
    "    # Make predictions\n",
    "    predictions_encoded = model.predict(new_data_features)\n",
    "    predictions = label_encoder.inverse_transform(predictions_encoded)\n",
    "\n",
    "    # Get probabilities for each class\n",
    "    probabilities = model.predict_proba(new_data_features)\n",
    "\n",
    "    # Create results DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        'Predicted_Type': predictions\n",
    "    })\n",
    "\n",
    "    # Add probability columns for each class\n",
    "    for i, class_name in enumerate(label_encoder.classes_):\n",
    "        results[f'{class_name}_Probability'] = probabilities[:, i]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6ce5f3-03a1-4140-9483-a2dd75e35f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel training and evaluation complete!\")\n",
    "print(\"To use this model for predictions:\")\n",
    "print(\"1. Load the model: model_data = pickle.load(open('message_classifier_model.pkl', 'rb'))\")\n",
    "print(\"2. Call: predict_message_type(model_data, new_data)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f64a52-9b16-4520-8233-9e96a71d028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a simple test prediction example\n",
    "print(\"\\nExample prediction code:\")\n",
    "print(\"import pickle\")\n",
    "print(\"model_data = pickle.load(open('message_classifier_model.pkl', 'rb'))\")\n",
    "print(\"# Create a sample input with same columns as the training data\")\n",
    "print(\"sample_data = pd.DataFrame({\")\n",
    "print(\"    'has_phone_number': [1, 0, 0],\")\n",
    "print(\"    'has_special_chars': [1, 1, 1],\")\n",
    "print(\"    # Add other features...\")\n",
    "print(\"})\")\n",
    "print(\"predictions = predict_message_type(model_data, sample_data)\")\n",
    "print(\"print(predictions)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
