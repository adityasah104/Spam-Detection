{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f442498-5f94-46ba-ad82-b6c07936f2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "from IPython.display import display\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler # Import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pickle # Import pickle\n",
    "from itertools import cycle # Import cycle\n",
    "# %%\n",
    "# Load data from CSV file\n",
    "df = pd.read_csv('processed_dataset.csv')\n",
    "# %%\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nSample of the dataset:\")\n",
    "print(df.head())\n",
    "# %%\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "# %%\n",
    "# Check unique values in 'type' column\n",
    "print(\"\\nUnique values in the classification column:\")\n",
    "# Print the actual column names to identify the correct one\n",
    "print(\"DataFrame columns:\", df.columns.tolist())\n",
    "# Assume the column is named 'type' based on common practice,\n",
    "# but replace 'type' with the actual column name if it's different\n",
    "if 'type' in df.columns:\n",
    "    print(df['type'].unique())\n",
    "else:\n",
    "    print(\"Column 'type' not found. Please check DataFrame columns.\")\n",
    "# %%\n",
    "# Standardize the type values - treat case insensitively and NaN as spam\n",
    "def standardize_type(x):\n",
    "    if pd.isna(x):  # Handle NaN values as spam\n",
    "        return 'spam'\n",
    "\n",
    "    if not isinstance(x, str):\n",
    "        x = str(x)  # Convert non-string types to string\n",
    "\n",
    "    x_lower = x.lower().strip()\n",
    "\n",
    "    # Exact match for main categories\n",
    "    if 'spam' in x_lower:\n",
    "        return 'spam'\n",
    "    elif 'ham' in x_lower:\n",
    "        return 'ham'\n",
    "    elif 'promo' in x_lower:\n",
    "        return 'promo'\n",
    "    else:\n",
    "        return x_lower  # Return as is for other categories\n",
    "\n",
    "correct_type_column_name = 'Type' # Assuming the column is named 'Type' based on 'Type                â€¦' in the global variables\n",
    "\n",
    "if correct_type_column_name in df.columns:\n",
    "    df['standardized_type'] = df[correct_type_column_name].apply(standardize_type)\n",
    "else:\n",
    "    # This block should ideally not be reached if the column name is correct\n",
    "    print(f\"Error: The column '{correct_type_column_name}' was not found in the DataFrame.\")\n",
    "    print(\"Please check the column names in df.columns.tolist() and update the code.\")\n",
    "# %%\n",
    "# Display distribution of standardized types\n",
    "print(\"\\nStandardized type distribution:\")\n",
    "print(df['standardized_type'].value_counts())\n",
    "# %%\n",
    "# Create a label encoder for the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "df['type_encoded'] = label_encoder.fit_transform(df['standardized_type'])\n",
    "\n",
    "# %%\n",
    "# Map the encoded values back to their original labels for reference\n",
    "encoded_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"\\nEncoded class mapping:\")\n",
    "for class_name, encoded_value in encoded_mapping.items():\n",
    "    print(f\"{class_name} -> {encoded_value}\")\n",
    "\n",
    "# %%\n",
    "# Define features (all columns except type-related and text columns)\n",
    "features = [col for col in df.columns if col not in ['type', 'text', 'standardized_type', 'type_encoded', correct_type_column_name]] # Exclude the original type column too\n",
    "print(\"\\nFeatures used for classification:\")\n",
    "print(features)\n",
    "\n",
    "# %%\n",
    "# Prepare features and target\n",
    "X = df[features]\n",
    "y = df['type_encoded']\n",
    "# %%\n",
    "# Split data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")\n",
    "\n",
    "# %%\n",
    "# Identify numeric and categorical columns based on the actual data types in X_train\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"\\nNumeric features:\", numeric_features)\n",
    "print(\"Categorical features:\", categorical_features)\n",
    "\n",
    "# Create preprocessing steps using ColumnTransformer\n",
    "# We'll scale numerical features and one-hot encode categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Apply StandardScaler to numerical features\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        # Apply OneHotEncoder to categorical features\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    # Drop any columns that are not explicitly handled (e.g., if 'text' column somehow got here)\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Create a pipeline that includes preprocessing and the model\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline - This applies preprocessing and then trains the model\n",
    "print(\"\\nTraining Random Forest model using Pipeline...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# %%\n",
    "# Evaluate model on training data using the pipeline\n",
    "train_preds = pipeline.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_preds)\n",
    "print(f\"\\nTraining accuracy (Pipeline): {train_accuracy:.3f}\")\n",
    "\n",
    "# %%\n",
    "# Evaluate model on test data using the pipeline\n",
    "test_preds = pipeline.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_preds)\n",
    "print(f\"Test accuracy (Pipeline): {test_accuracy:.3f}\")\n",
    "\n",
    "# %%\n",
    "# Get the original class names for display\n",
    "original_class_names = label_encoder.classes_\n",
    "\n",
    "# %%\n",
    "# Print detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, test_preds, target_names=original_class_names))\n",
    "\n",
    "# %%\n",
    "# Display confusion matrix\n",
    "cm = confusion_matrix(y_test, test_preds)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=original_class_names,\n",
    "            yticklabels=original_class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_multiclass.png')\n",
    "print(\"\\nConfusion matrix saved as 'confusion_matrix_multiclass.png'\")\n",
    "\n",
    "# %%\n",
    "# Feature importance - Note: Getting feature importance from a pipeline with\n",
    "# ColumnTransformer is slightly more involved as the preprocessor transforms\n",
    "# the features. We'll get importance from the trained classifier component,\n",
    "# but the names will correspond to the transformed features.\n",
    "# A more complex approach is needed to map back to original feature names\n",
    "# for one-hot encoded features. For simplicity, we'll get importance from\n",
    "# the classifier and match with processed feature names.\n",
    "\n",
    "# Get feature importances from the trained classifier\n",
    "classifier = pipeline.named_steps['classifier']\n",
    "importances = classifier.feature_importances_\n",
    "\n",
    "# Get feature names after preprocessing (this includes scaled numerical and one-hot encoded categorical)\n",
    "# This is a bit tricky with older scikit-learn versions. For newer versions,\n",
    "# preprocessor.get_feature_names_out() is available. If using an older version,\n",
    "# you might need to manually construct the names.\n",
    "try:\n",
    "    processed_feature_names = list(pipeline.named_steps['preprocessor'].get_feature_names_out(features))\n",
    "except AttributeError:\n",
    "    # Fallback for older scikit-learn versions - this is an approximation\n",
    "    # Numerical features keep their names, categorical features become name_categoryvalue\n",
    "    processed_feature_names = []\n",
    "    # Add numerical feature names\n",
    "    processed_feature_names.extend(numeric_features)\n",
    "    # Add categorical feature names - this requires fitting and inspecting the OneHotEncoder\n",
    "    ohe = pipeline.named_steps['preprocessor'].named_transformers_['cat']\n",
    "    for i, cat_col in enumerate(categorical_features):\n",
    "        # Check if categories_ attribute exists\n",
    "        if hasattr(ohe, 'categories_') and i < len(ohe.categories_):\n",
    "             processed_feature_names.extend([f\"{cat_col}_{cat}\" for cat in ohe.categories_[i]])\n",
    "        else:\n",
    "             # Fallback if categories_ is not available or indexing fails\n",
    "             print(f\"Warning: Could not determine categories for {cat_col}. Feature names might be incorrect.\")\n",
    "             # Add a placeholder or just the column name multiple times if needed\n",
    "             processed_feature_names.extend([f\"processed_{cat_col}_{j}\" for j in range(ohe.transform(X_train[[cat_col]]).shape[1])])\n",
    "\n",
    "\n",
    "if len(importances) == len(processed_feature_names):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': processed_feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "\n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(feature_importance)\n",
    "\n",
    "    plt.figure(figsize=(12, min(50, len(feature_importance) * 0.5))) # Adjust figure height based on number of features\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance.head(20)) # Plotting top 20 for clarity\n",
    "    plt.title('Feature Importance (Processed Features)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance_multiclass.png')\n",
    "    print(\"Feature importance plot saved as 'feature_importance_multiclass.png'\")\n",
    "\n",
    "    # Display top 5 most important features\n",
    "    print(\"\\nTop 5 most important features:\")\n",
    "    print(feature_importance.head(5))\n",
    "else:\n",
    "    print(\"Could not match feature importances to processed feature names.\")\n",
    "    print(\"Number of importances:\", len(importances))\n",
    "    print(\"Number of processed feature names:\", len(processed_feature_names))\n",
    "    print(\"Feature importances:\", importances) # Print raw importances\n",
    "\n",
    "# %%\n",
    "# The tune_hyperparameters function can also be updated to use the pipeline\n",
    "def tune_hyperparameters():\n",
    "    print(\"\\nPerforming hyperparameter tuning...\")\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    # Define the parameter grid. Note the parameter names now include the pipeline step name ('classifier__')\n",
    "    param_grid = {\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10],\n",
    "        'classifier__min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    # Create a new pipeline instance for grid search\n",
    "    # Use the same preprocessor definition as above\n",
    "    grid_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor), # Use the preprocessor defined earlier\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        grid_pipeline, # Pass the pipeline to GridSearchCV\n",
    "        param_grid=param_grid,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "\n",
    "    # Fit GridSearchCV on the training data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_:.3f}\")\n",
    "\n",
    "    # The best estimator from grid search is a fitted pipeline\n",
    "    best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the best pipeline on the test set\n",
    "    best_preds = best_pipeline.predict(X_test)\n",
    "    best_accuracy = accuracy_score(y_test, best_preds)\n",
    "    print(f\"Tuned model test accuracy (Pipeline): {best_accuracy:.3f}\")\n",
    "\n",
    "    return best_pipeline # Return the best fitted pipeline\n",
    "# %%\n",
    "# Calculate and Plot ROC curve for multiclass\n",
    "\n",
    "# Get predicted probabilities for the test set\n",
    "# The pipeline's predict_proba method handles preprocessing internally\n",
    "test_probs = pipeline.predict_proba(X_test)\n",
    "\n",
    "# Calculate ROC AUC score for multiclass (using One-vs-Rest strategy)\n",
    "# average='ovr' computes the AUC of each class against the rest and takes the average.\n",
    "# multi_class='ovr' specifies the strategy for multiclass.\n",
    "try:\n",
    "    roc_auc_ovr = roc_auc_score(y_test, test_probs, average='ovr', multi_class='ovr')\n",
    "    print(f\"\\nROC AUC (One-vs-Rest): {roc_auc_ovr:.3f}\")\n",
    "except ValueError as e:\n",
    "    print(f\"\\nCould not calculate ROC AUC: {e}\")\n",
    "    print(\"This might happen if there is only one class present in the test set.\")\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "# y_test is the true labels (encoded integers)\n",
    "# test_probs are the predicted probabilities for each class\n",
    "fpr = dict() # Dictionary to store False Positive Rate for each class\n",
    "tpr = dict() # Dictionary to store True Positive Rate for each class\n",
    "roc_auc = dict() # Dictionary to store ROC AUC score for each class\n",
    "\n",
    "# Get the number of classes\n",
    "n_classes = len(label_encoder.classes_)\n",
    "\n",
    "# Iterate through each class\n",
    "for i in range(n_classes):\n",
    "    # For each class, we compare it against all other classes (One-vs-Rest)\n",
    "    # We treat the current class as positive (1) and all others as negative (0)\n",
    "    # We need to convert y_test to a binary format for each class\n",
    "    # (1 if the true label is the current class, 0 otherwise)\n",
    "    y_true_binary = (y_test == i).astype(int)\n",
    "\n",
    "    # Get the probability for the current class\n",
    "    y_score = test_probs[:, i]\n",
    "\n",
    "    # Compute ROC curve: fpr, tpr, thresholds\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_binary, y_score)\n",
    "\n",
    "    # Compute Area Under the curve (AUC) using the calculated fpr and tpr\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves for each class\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'red', 'purple', 'brown']) # Define colors for plots\n",
    "\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} ({1:.2f})'.format(label_encoder.classes_[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.50)') # Plot random guess line\n",
    "plt.xlim([0.0, 1.0]) # Set x-axis limits\n",
    "plt.ylim([0.0, 1.05]) # Set y-axis limits slightly above 1\n",
    "plt.xlabel('False Positive Rate') # Label x-axis\n",
    "plt.ylabel('True Positive Rate') # Label y-axis\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Multiclass (One-vs-Rest)') # Set title\n",
    "plt.legend(loc=\"lower right\") # Display legend\n",
    "plt.grid(True) # Add grid\n",
    "plt.tight_layout() # Adjust layout\n",
    "plt.savefig('roc_curve_multiclass_ovr.png') # Save the plot\n",
    "print(\"\\nROC curve plot saved as 'roc_curve_multiclass_ovr.png'\")\n",
    "\n",
    "# %%\n",
    "# Save the pipeline and label encoder\n",
    "# Use the 'pipeline' object fitted earlier or the 'best_pipeline' if tuning was run\n",
    "final_pipeline_to_save = pipeline # Or best_pipeline if tuning was executed\n",
    "\n",
    "with open('message_classifier_model.pkl', 'wb') as file:\n",
    "    # Save the pipeline, label encoder, and original feature names used\n",
    "    pickle.dump({'model': final_pipeline_to_save, 'label_encoder': label_encoder, 'features': features}, file)\n",
    "print(\"\\nPipeline saved as 'message_classifier_model.pkl'\")\n",
    "\n",
    "# %%\n",
    "# Function to make predictions on new data using the loaded pipeline\n",
    "def predict_message_type(model_data, new_data):\n",
    "    # Extract pipeline components\n",
    "    pipeline = model_data['model'] # The model is now the pipeline\n",
    "    label_encoder = model_data['label_encoder']\n",
    "    original_features = model_data['features'] # List of original feature column names\n",
    "\n",
    "    # Ensure new_data has all original feature columns that the pipeline expects\n",
    "    # Create a DataFrame with all expected columns, filling missing ones as needed\n",
    "    # The values used for missing features should be handled appropriately by your preprocessor\n",
    "    # (e.g., StandardScaler will handle NaNs if present, OneHotEncoder handle_unknown='ignore')\n",
    "    # However, it's best practice to ensure the input data matches the training data structure.\n",
    "    # For this example, we'll create a dummy DataFrame and populate it.\n",
    "    # Ensure the dtypes match the training data where possible.\n",
    "    processed_new_data = pd.DataFrame(columns=original_features)\n",
    "\n",
    "    # Populate with data from new_data, adding missing columns with default values\n",
    "    for col in original_features:\n",
    "        if col in new_data.columns:\n",
    "            processed_new_data[col] = new_data[col]\n",
    "        else:\n",
    "            # Add missing column with a default value.\n",
    "            # A better approach might be to determine the dtype from the training data\n",
    "            # and use an appropriate default (0 for numeric, '' or None for categorical).\n",
    "            # For simplicity, we'll add 0. You might need to adjust this.\n",
    "             # Attempt to infer dtype from training features\n",
    "            if col in X_train.columns:\n",
    "                 if X_train[col].dtype in ['int64', 'float64']:\n",
    "                     processed_new_data[col] = 0\n",
    "                 elif X_train[col].dtype == 'object':\n",
    "                      # Use a placeholder string if column was categorical\n",
    "                      processed_new_data[col] = '' # Or a specific category if applicable\n",
    "                 else:\n",
    "                      processed_new_data[col] = 0 # Default fallback\n",
    "            else:\n",
    "                 processed_new_data[col] = 0 # Default if column not in X_train (shouldn't happen if features list is correct)\n",
    "\n",
    "    # Ensure row count matches input data (if new_data had multiple rows)\n",
    "    if len(processed_new_data) != len(new_data):\n",
    "         # This case handles adding missing columns correctly for multiple rows\n",
    "         processed_new_data = pd.DataFrame(index=new_data.index, columns=original_features)\n",
    "         for col in original_features:\n",
    "            if col in new_data.columns:\n",
    "                processed_new_data[col] = new_data[col]\n",
    "            else:\n",
    "                if col in X_train.columns:\n",
    "                    if X_train[col].dtype in ['int64', 'float64']:\n",
    "                        processed_new_data[col] = 0\n",
    "                    elif X_train[col].dtype == 'object':\n",
    "                        processed_new_data[col] = ''\n",
    "                    else:\n",
    "                        processed_new_data[col] = 0\n",
    "                else:\n",
    "                    processed_new_data[col] = 0\n",
    "\n",
    "\n",
    "    # Make predictions using the pipeline (this includes preprocessing)\n",
    "    predictions_encoded = pipeline.predict(processed_new_data)\n",
    "    predictions = label_encoder.inverse_transform(predictions_encoded)\n",
    "\n",
    "    # Get probabilities for each class\n",
    "    probabilities = pipeline.predict_proba(processed_new_data)\n",
    "\n",
    "    # Create results DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        'Predicted_Type': predictions\n",
    "    })\n",
    "\n",
    "    # Add probability columns for each class\n",
    "    for i, class_name in enumerate(label_encoder.classes_):\n",
    "        results[f'{class_name}_Probability'] = probabilities[:, i]\n",
    "\n",
    "    # Add original data for context (optional)\n",
    "    # results = pd.concat([new_data.reset_index(drop=True), results], axis=1)\n",
    "\n",
    "    return results\n",
    "# %%\n",
    "print(\"\\nModel training and evaluation complete!\")\n",
    "print(\"To use this model for predictions:\")\n",
    "print(\"1. Load the model: model_data = pickle.load(open('message_classifier_model.pkl', 'rb'))\")\n",
    "print(\"2. Create new data with the same columns used for training (or a subset that will be handled by the function's logic).\")\n",
    "print(\"   Example: sample_data = pd.DataFrame({'has_phone_number': [1], 'word_count': [15], ...})\")\n",
    "print(\"3. Call: predict_message_type(model_data, sample_data)\")\n",
    "\n",
    "# %%\n",
    "# Add a simple test prediction example\n",
    "print(\"\\nExample prediction code:\")\n",
    "print(\"import pickle\")\n",
    "print(\"import pandas as pd\")\n",
    "# Load the model data from the saved file\n",
    "model_data = pickle.load(open('message_classifier_model.pkl', 'rb'))\n",
    "print(\"model_data = pickle.load(open('message_classifier_model.pkl', 'rb'))\")\n",
    "\n",
    "# Create a sample input with same columns as the training data (using first row of X_test as example)\n",
    "# Replace this with actual new data you want to predict on\n",
    "if not X_test.empty:\n",
    "    sample_data = X_test.head(1).copy()\n",
    "    # Modify values if you want to test a different input\n",
    "    # sample_data['has_phone_number'] = 1\n",
    "    # sample_data['avg_word_length'] = 5.0\n",
    "    # ... modify other relevant features\n",
    "    print(\"\\nUsing a sample from X_test for prediction example:\")\n",
    "    print(sample_data)\n",
    "    predictions = predict_message_type(model_data, sample_data)\n",
    "    print(\"\\nPrediction results:\")\n",
    "    print(predictions)\n",
    "else:\n",
    "    print(\"\\nX_test is empty, skipping prediction example.\")\n",
    "    print(\"# Create a sample input with same columns as the training data\")\n",
    "    print(\"sample_data = pd.DataFrame({\")\n",
    "    # List some expected features - you'll need to provide values\n",
    "    if features:\n",
    "        for i, feat in enumerate(features[:5]): # Show top 5 features\n",
    "            # Provide a placeholder value based on expected type (int/float 0, str '')\n",
    "            default_val = 0 if feat in numeric_features else ''\n",
    "            print(f\"    '{feat}': [{default_val}]{',' if i < len(features[:5]) - 1 else ''}\")\n",
    "    else:\n",
    "        print(\"    # No features defined in the loaded model.\")\n",
    "    print(\"    # Add other features as needed based on the 'features' list\")\n",
    "    print(\"})\")\n",
    "    print(\"# predictions = predict_message_type(model_data, sample_data)\")\n",
    "    # print(\"# print(predictions)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a66cd-dbed-4ebc-b618-0aba70e8834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Calculate ROC curve and AUC for a binary scenario (e.g., Spam vs Ham)\n",
    "\n",
    "# This code assumes you have the following variables available from previous cells:\n",
    "# - pipeline: Your fitted scikit-learn pipeline\n",
    "# - X_test: Test features (original features)\n",
    "# - y_test: Test labels (encoded integers)\n",
    "# - label_encoder: The fitted LabelEncoder\n",
    "\n",
    "print(\"\\nCalculating and plotting binary ROC curve for 'Spam' vs 'Ham'...\")\n",
    "\n",
    "# We need the predicted probabilities for the test set.\n",
    "# The pipeline's predict_proba method handles preprocessing internally.\n",
    "try:\n",
    "    test_probs = pipeline.predict_proba(X_test)\n",
    "except Exception as e:\n",
    "    print(f\"Error getting predicted probabilities from pipeline: {e}\")\n",
    "    test_probs = None # Indicate failure\n",
    "\n",
    "if test_probs is not None:\n",
    "    # Find the index corresponding to the 'spam' class in the label encoder's classes.\n",
    "    try:\n",
    "        spam_class_index = list(label_encoder.classes_).index('spam')\n",
    "        print(f\"Found 'spam' class at index: {spam_class_index}\")\n",
    "    except ValueError:\n",
    "        print(\"Error: 'spam' class not found in label encoder classes. Cannot proceed with binary ROC.\")\n",
    "        spam_class_index = None # Indicate that 'spam' was not found\n",
    "\n",
    "    if spam_class_index is not None:\n",
    "        # Get the predicted probabilities specifically for the 'spam' class\n",
    "        y_test_proba_spam = test_probs[:, spam_class_index]\n",
    "\n",
    "        # Filter y_test and y_test_proba to only include samples from 'ham' and 'spam' classes\n",
    "        # Find the encoded labels for 'ham' and 'spam'\n",
    "        try:\n",
    "            ham_encoded_label = label_encoder.transform(['ham'])[0] if 'ham' in label_encoder.classes_ else None\n",
    "            spam_encoded_label = label_encoder.transform(['spam'])[0] if 'spam' in label_encoder.classes_ else None\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting encoded labels for 'ham' or 'spam': {e}. Skipping binary ROC.\")\n",
    "            ham_encoded_label = None\n",
    "            spam_encoded_label = None\n",
    "\n",
    "\n",
    "        if ham_encoded_label is not None and spam_encoded_label is not None:\n",
    "            # Create a mask for test samples that are either 'ham' or 'spam' (using their encoded labels)\n",
    "            ham_spam_mask_test = (y_test == ham_encoded_label) | (y_test == spam_encoded_label)\n",
    "\n",
    "            # Apply the mask to filter the true labels and predicted probabilities\n",
    "            y_test_ham_spam_encoded = y_test[ham_spam_mask_test]\n",
    "            y_test_proba_ham_spam = y_test_proba_spam[ham_spam_mask_test]\n",
    "\n",
    "            # Convert the filtered true labels to binary: 'spam' (positive) is 1, 'ham' (negative) is 0\n",
    "            y_test_binary = (y_test_ham_spam_encoded == spam_encoded_label).astype(int)\n",
    "\n",
    "            # Check if there are both positive (spam) and negative (ham) samples in the filtered data\n",
    "            if len(np.unique(y_test_binary)) > 1:\n",
    "                # Calculate ROC curve\n",
    "                from sklearn.metrics import roc_curve, auc\n",
    "                fpr, tpr, thresholds = roc_curve(y_test_binary, y_test_proba_ham_spam)\n",
    "\n",
    "                # Calculate Area Under the ROC Curve (AUC)\n",
    "                roc_auc = auc(fpr, tpr)\n",
    "\n",
    "                print(f\"\\nArea under ROC Curve (AUC) for 'Spam' class (vs 'Ham'): {roc_auc:.4f}\")\n",
    "\n",
    "                # Plot the ROC curve\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "                plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random (AUC = 0.50)')\n",
    "                plt.xlim([0.0, 1.0])\n",
    "                plt.ylim([0.0, 1.05])\n",
    "                plt.xlabel('False Positive Rate')\n",
    "                plt.ylabel('True Positive Rate')\n",
    "                plt.title('Receiver Operating Characteristic (ROC) Curve for Spam (vs Ham)')\n",
    "                plt.legend(loc=\"lower right\")\n",
    "                plt.grid(True)\n",
    "                plt.tight_layout()\n",
    "                plt.savefig('roc_curve_spam_vs_ham.png')\n",
    "                print(\"ROC curve plot saved as 'roc_curve_spam_vs_ham.png'\")\n",
    "\n",
    "            else:\n",
    "                 print(\"\\nCannot plot binary ROC for 'Spam' vs 'Ham': Filtered test set does not contain both classes.\")\n",
    "                 print(f\"Unique values in filtered y_test_binary: {np.unique(y_test_binary)}\")\n",
    "        else:\n",
    "             print(\"\\nCould not get encoded labels for 'ham' or 'spam'. Skipping binary ROC plot.\")\n",
    "    # %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d3fe9-7057-4e43-badd-a8f56acfe425",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
